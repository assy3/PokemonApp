{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ポケモンタイプ学習.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nalgo-intern/team-b/blob/master/%E3%83%9D%E3%82%B1%E3%83%A2%E3%83%B3%E3%82%BF%E3%82%A4%E3%83%97%E5%AD%A6%E7%BF%92.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dI3qEKO9RZzG",
        "colab_type": "text"
      },
      "source": [
        "#driveからデータを取得"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s2qcKtYZOdvE",
        "colab_type": "code",
        "outputId": "cca349c1-8e31-44d5-e64d-778ff4a19199",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 532
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    729\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 730\u001b[0;31m                 \u001b[0mident\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdin_socket\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    731\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/jupyter_client/session.py\u001b[0m in \u001b[0;36mrecv\u001b[0;34m(self, socket, mode, content, copy)\u001b[0m\n\u001b[1;32m    802\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 803\u001b[0;31m             \u001b[0mmsg_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_multipart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    804\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mzmq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mZMQError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/zmq/sugar/socket.py\u001b[0m in \u001b[0;36mrecv_multipart\u001b[0;34m(self, flags, copy, track)\u001b[0m\n\u001b[1;32m    465\u001b[0m         \"\"\"\n\u001b[0;32m--> 466\u001b[0;31m         \u001b[0mparts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrack\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrack\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    467\u001b[0m         \u001b[0;31m# have first part already, only loop while more to receive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.recv\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.recv\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket._recv_copy\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/zmq/backend/cython/checkrc.pxd\u001b[0m in \u001b[0;36mzmq.backend.cython.checkrc._check_rc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-d5df0069828e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms)\u001b[0m\n\u001b[1;32m    202\u001b[0m       \u001b[0;31m# Not already authorized, so do the authorization dance.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m       \u001b[0mauth_prompt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'\\n\\nEnter your authorization code:\\n'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m       \u001b[0md\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_getpass\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetpass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mauth_prompt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    205\u001b[0m   \u001b[0md\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msendcontrol\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'z'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m   \u001b[0md\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mu'Stopped'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mgetpass\u001b[0;34m(self, prompt, stream)\u001b[0m\n\u001b[1;32m    686\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    687\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 688\u001b[0;31m             \u001b[0mpassword\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    689\u001b[0m         )\n\u001b[1;32m    690\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    733\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    734\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 735\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    736\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    737\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tHku4nfJX1wN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cp -R /content/drive/My\\ Drive/dataset /content/\n",
        "!mkdir learned_data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GKwtRStHC1wQ",
        "colab_type": "text"
      },
      "source": [
        "#水増し"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zk-iX7BGCrg6",
        "colab_type": "code",
        "outputId": "030e3e43-b0f2-491a-fab9-575791b5d200",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        }
      },
      "source": [
        "#画像の水増し\n",
        "\n",
        "import os\n",
        "import glob\n",
        "import numpy as np\n",
        "from keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array, array_to_img\n",
        "\n",
        "# 画像を拡張する関数\n",
        "def draw_images(generator, x, dir_name, index):\n",
        "    save_name = 'extened-' + str(index)\n",
        "    g = generator.flow(x, batch_size=1, save_to_dir=output_dir,\n",
        "                       save_prefix=save_name, save_format='jpg')\n",
        "\n",
        "    # 1つの入力画像から何枚拡張するかを指定（今回は50枚）\n",
        "    for i in range(50):\n",
        "        bach = g.next()\n",
        "\n",
        "types =[\"normal\", \"fire\", \"water\", \"grass\", \"electric\", \"ice\", \"fighting\", \"poison\", \"ground\", \"flying\", \"psychic\", \"bug\", \"rock\", \"ghost\", \"dragon\"]\n",
        "base_dir = './dataset/'\n",
        "for i in types:\n",
        "    print(i)\n",
        "    # 出力先ディレクトリの設定\n",
        "    output_dir = base_dir + i\n",
        "    \n",
        "    if not(os.path.exists(output_dir)):\n",
        "        os.mkdir(output_dir)\n",
        "    \n",
        "    # 拡張する画像の読み込み\n",
        "    images = glob.glob(os.path.join(base_dir + i, \"*.jpg\"))\n",
        "    \n",
        "    # ImageDataGeneratorを定義\n",
        "    datagen = ImageDataGenerator(rotation_range=30,\n",
        "                                width_shift_range=20,\n",
        "                                height_shift_range=0.,\n",
        "                                zoom_range=0.1,\n",
        "                                horizontal_flip=True,\n",
        "                                vertical_flip=True)\n",
        "    \n",
        "    # 読み込んだ画像を順に拡張\n",
        "    for i in range(len(images)):\n",
        "        img = load_img(images[i])\n",
        "        img = img.resize((250, 250))\n",
        "        x = img_to_array(img)\n",
        "        x = np.expand_dims(x, axis=0)\n",
        "        draw_images(datagen, x, output_dir, i)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "normal\n",
            "fire\n",
            "water\n",
            "grass\n",
            "electric\n",
            "ice\n",
            "fighting\n",
            "poison\n",
            "ground\n",
            "flying\n",
            "psychic\n",
            "bug\n",
            "rock\n",
            "ghost\n",
            "dragon\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EkJT-kQnRepn",
        "colab_type": "text"
      },
      "source": [
        "#データセットを作成"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "e3335c28-1e1d-4a7f-dfa4-386cb958a323",
        "id": "g5qVVHWZWpY7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 277
        }
      },
      "source": [
        "!pip install -U numpy"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting numpy\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/75/92/57179ed45307ec6179e344231c47da7f3f3da9e2eee5c8ab506bd279ce4e/numpy-1.17.1-cp36-cp36m-manylinux1_x86_64.whl (20.4MB)\n",
            "\u001b[K     |████████████████████████████████| 20.4MB 2.8MB/s \n",
            "\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: numpy\n",
            "  Found existing installation: numpy 1.16.4\n",
            "    Uninstalling numpy-1.16.4:\n",
            "      Successfully uninstalled numpy-1.16.4\n",
            "Successfully installed numpy-1.17.1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CqRnDb_56vBZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from PIL import Image\n",
        "import os, glob\n",
        "import numpy as np\n",
        "import random, math\n",
        "\n",
        "root_dir = \"./dataset\"\n",
        "types =[\"normal\", \"fire\", \"water\", \"grass\", \"electric\", \"ice\", \"fighting\", \"poison\", \"ground\", \"flying\", \"psychic\", \"bug\", \"rock\", \"ghost\", \"dragon\"]\n",
        "\n",
        "X = []\n",
        "Y = []\n",
        "\n",
        "def make_sample(files):\n",
        "    global X, Y\n",
        "    X = []\n",
        "    Y = []\n",
        "    for cat, fname in files:\n",
        "        add_sample(cat, fname)\n",
        "    return np.array(X), np.array(Y)\n",
        "\n",
        "\n",
        "def add_sample(cat, fname):\n",
        "    img = Image.open(fname)\n",
        "    img = img.convert(\"RGB\")\n",
        "    img = img.resize((120, 120))\n",
        "    data = np.asarray(img)\n",
        "    X.append(data)\n",
        "    Y.append(cat)\n",
        "\n",
        "allfiles = []\n",
        "\n",
        "for idx, cat in enumerate(types):\n",
        "    image_dir = root_dir + \"/\" + cat\n",
        "    files = glob.glob(image_dir + \"/*.jpg\")\n",
        "    for f in files:\n",
        "        allfiles.append((idx, f))\n",
        "\n",
        "random.shuffle(allfiles)\n",
        "th = math.floor(len(allfiles) * 0.8)\n",
        "train = allfiles[0:th]\n",
        "test = allfiles[th:]\n",
        "X_train, y_train = make_sample(train)\n",
        "np.save(\"./dataset_X_train.npy\", X_train)\n",
        "np.save(\"./dataset_y_train.npy\", y_train)\n",
        "X_test, y_test = make_sample(test)\n",
        "np.save(\"./dataset_X_test.npy\", X_test)\n",
        "np.save(\"./dataset_y_test.npy\", y_test)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n0H8LUHSRjhu",
        "colab_type": "text"
      },
      "source": [
        "#学習"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lGW91eazHR9d",
        "colab_type": "code",
        "outputId": "cf3eb7de-b34a-4629-d654-a2228c101ff6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 277
        }
      },
      "source": [
        "!pip install numpy==1.16.2"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting numpy==1.16.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/35/d5/4f8410ac303e690144f0a0603c4b8fd3b986feb2749c435f7cdbb288f17e/numpy-1.16.2-cp36-cp36m-manylinux1_x86_64.whl (17.3MB)\n",
            "\u001b[K     |████████████████████████████████| 17.3MB 2.8MB/s \n",
            "\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: numpy\n",
            "  Found existing installation: numpy 1.17.1\n",
            "    Uninstalling numpy-1.17.1:\n",
            "      Successfully uninstalled numpy-1.17.1\n",
            "Successfully installed numpy-1.16.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fx_QuEgXBttq",
        "colab_type": "code",
        "outputId": "5194f7c6-205e-4a71-d90c-559a55345742",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import keras\n",
        "from keras.datasets import cifar10\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras import optimizers\n",
        "import numpy as np\n",
        "\n",
        "num_classes = 15\n",
        "im_rows = 120\n",
        "im_cols = 120\n",
        "in_shape = (im_rows, im_cols, 3)\n",
        "\n",
        "# データを読み込む --- (*1)\n",
        "X_train = np.load(\"./dataset_X_train.npy\")\n",
        "y_train = np.load(\"./dataset_y_train.npy\")\n",
        "X_test = np.load(\"./dataset_X_test.npy\")\n",
        "y_test = np.load(\"./dataset_y_test.npy\")\n",
        "\n",
        "# データを正規化 --- (*2)\n",
        "X_train = X_train.astype('float32') / 255\n",
        "X_test = X_test.astype('float32') / 255\n",
        "# ラベルデータをOne-Hot形式に変換\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
        "\n",
        "## モデルを定義 --- (*3)\n",
        "## 51行目のDenseの値を変えてみたり35-40行目を増やしたり減らしたり、Conv2Dの最初の引数を変えたり、Dropoutの引数を変えたり\n",
        "#model = Sequential()\n",
        "#model.add(Conv2D(32, (3, 3), padding='same',\n",
        "#                 input_shape=in_shape))\n",
        "#model.add(Activation('relu'))\n",
        "#model.add(Conv2D(32, (3, 3)))\n",
        "#model.add(Activation('relu'))\n",
        "##model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "##model.add(Dropout(0.5))\n",
        "#\n",
        "#model.add(Conv2D(64, (3, 3), padding='same'))\n",
        "#model.add(Activation('relu'))\n",
        "#model.add(Conv2D(128, (3, 3)))\n",
        "#model.add(Activation('relu'))\n",
        "##model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "##model.add(Dropout(0.5))\n",
        "#\n",
        "##model.add(Conv2D(128, (3, 3), padding='same')\n",
        "##model.add(Activation('relu'))\n",
        "##model.add(Conv2D(128, (3, 3)))\n",
        "##model.add(Activation('relu'))\n",
        "##model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "##model.add(Dropout(0.25))\n",
        "#\n",
        "#model.add(Flatten())\n",
        "#model.add(Dense(512))\n",
        "##model.add(Dense(128))\n",
        "#model.add(Activation('relu'))\n",
        "#model.add(Dropout(0.5))\n",
        "#model.add(Dense(num_classes))\n",
        "#model.add(Activation('sigmoid'))\n",
        "#\n",
        "## モデルをコンパイル --- (*4)\n",
        "#model.compile(\n",
        "#    loss='categorical_crossentropy',\n",
        "#    optimizer='adam',\n",
        "#    metrics=['accuracy'])\n",
        "\n",
        "#綾鷹\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32,(3,3),activation=\"relu\",input_shape=(120,120,3)))\n",
        "model.add(MaxPooling2D((2,2)))\n",
        "model.add(Conv2D(64,(3,3),activation=\"relu\"))\n",
        "model.add(MaxPooling2D((2,2)))\n",
        "model.add(Dropout(0.75))\n",
        "model.add(Conv2D(128,(3,3),activation=\"relu\"))\n",
        "model.add(MaxPooling2D((2,2)))\n",
        "model.add(Conv2D(128,(3,3),activation=\"relu\"))\n",
        "model.add(MaxPooling2D((2,2)))\n",
        "model.add(Flatten())\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(512,activation=\"relu\"))\n",
        "model.add(Dense(15,activation=\"softmax\"))\n",
        "model.summary()\n",
        "model.compile(loss=\"categorical_crossentropy\",\n",
        "              optimizer=optimizers.RMSprop(lr=1e-5),\n",
        "              metrics=[\"acc\"])\n",
        "\n",
        "# 学習を実行 --- (*5)\n",
        "#batch_sizeやepochsの数を変えたり\n",
        "hist = model.fit(X_train, y_train,\n",
        "    batch_size=128, epochs=200,\n",
        "    verbose=1,\n",
        "    validation_data=(X_test, y_test))\n",
        "\n",
        "# モデルを評価 --- (*6)\n",
        "score = model.evaluate(X_test, y_test, verbose=1)\n",
        "print('正解率=', score[1], 'loss=', score[0])\n",
        "\n",
        "# 学習の様子をグラフへ描画 --- (*7)\n",
        "plt.plot(hist.history['acc'])\n",
        "plt.plot(hist.history['val_acc'])\n",
        "plt.title('Accuracy')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()\n",
        "plt.plot(hist.history['loss'])\n",
        "plt.plot(hist.history['val_loss'])\n",
        "plt.title('Loss')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "#モデル・重みの保存\n",
        "json_string = model.model.to_json()\n",
        "open('./learned_data/data.json', 'w').write(json_string)\n",
        "\n",
        "hdf5_file = \"./learned_data/data.hdf5\"\n",
        "model.model.save_weights(hdf5_file)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n",
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0827 01:12:01.125983 139919141156736 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "W0827 01:12:01.176618 139919141156736 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "W0827 01:12:01.206977 139919141156736 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "W0827 01:12:01.247435 139919141156736 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n",
            "W0827 01:12:01.267344 139919141156736 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "W0827 01:12:01.276427 139919141156736 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "W0827 01:12:01.277428 139919141156736 nn_ops.py:4224] Large dropout rate: 0.75 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
            "W0827 01:12:01.408983 139919141156736 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "W0827 01:12:01.415359 139919141156736 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3376: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "W0827 01:12:01.420935 139919141156736 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_1 (Conv2D)            (None, 118, 118, 32)      896       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 59, 59, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 57, 57, 64)        18496     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 28, 28, 64)        0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 28, 28, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 26, 26, 128)       73856     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 13, 13, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 11, 11, 128)       147584    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2 (None, 5, 5, 128)         0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 3200)              0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 3200)              0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 512)               1638912   \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 15)                7695      \n",
            "=================================================================\n",
            "Total params: 1,887,439\n",
            "Trainable params: 1,887,439\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Train on 58781 samples, validate on 14696 samples\n",
            "Epoch 1/20\n",
            " 4352/58781 [=>............................] - ETA: 2:31 - loss: 0.2469 - acc: 0.9333"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KZZDfcFF-S0c",
        "colab_type": "text"
      },
      "source": [
        "#バックアップ"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MZVhvb-9-RTZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cp -R ./learned_data ./drive/My\\ Drive\n",
        "!cp dataset*.npy ./drive/My\\ Drive"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}